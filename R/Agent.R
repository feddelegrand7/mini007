#' Agent: A General-Purpose LLM Agent
#'
#' @description
#' The `Agent` class defines a modular LLM-based agent capable of responding to prompts using a defined role/instruction.
#' It wraps an OpenAI-compatible chat model via the [`ellmer`](https://github.com/llrs/ellmer) package.
#'
#' Each agent maintains its own message history and unique identity.
#'
#' @importFrom R6 R6Class
#' @importFrom uuid UUIDgenerate
#' @importFrom checkmate assert_string assert_flag assert_character assert_integerish
#' @importFrom cli cli_abort cli_alert_success cli_alert_warning cli_alert_info cli_rule cli_text cli_ul
#' @export
Agent <- R6::R6Class(
  classname = "Agent",

  public = list(
    #' @description
    #' Initializes a new Agent with a specific role/instruction.
    #'
    #' @param name A short identifier for the agent (e.g. `"translator"`).
    #' @param instruction The system prompt that defines the agent's role.
    #' @param llm_object The LLM object generate by ellmer (eg. output of ellmer::chat_openai)
    #' @examples
    #'   # An API KEY is required in order to invoke the Agent
    #'   openai_4_1_mini <- ellmer::chat(
    #'     name = "openai/gpt-4.1-mini",
    #'     api_key = Sys.getenv("OPENAI_API_KEY"),
    #'     echo = "none"
    #'   )
    #'
    #'   polar_bear_researcher <- Agent$new(
    #'     name = "POLAR BEAR RESEARCHER",
    #'     instruction = paste0(
    #'     "You are an expert in polar bears, ",
    #'     "you task is to collect information about polar bears. Answer in 1 sentence max."
    #'     ),
    #'     llm_object = openai_4_1_mini
    #'   )
    #'
    initialize = function(name, instruction, llm_object) {
      checkmate::assert_string(name)
      checkmate::assert_string(instruction)

      if (!"Chat" %in% class(llm_object)) {
        cli::cli_abort("The llm_object must be generated by ellmer")
      }

      self$name <- name
      self$instruction <- instruction
      self$llm_object <- llm_object$clone(deep = TRUE)

      meta_data <- self$llm_object$get_provider()
      self$model_provider <- meta_data@name
      self$model_name <- meta_data@model

      self$llm_object$set_system_prompt(value = instruction)

      private$._messages <- list(
        list(role = "system", content = instruction)
      )

      self$agent_id <- uuid::UUIDgenerate()

      self$budget <- NULL
    },

    #' @description
    #' Sends a user prompt to the agent and returns the assistant's response.
    #'
    #' @param prompt A character string prompt for the agent to respond to.
    #' @return The LLM-generated response as a character string.
    #' @examples \dontrun{
    #' # An API KEY is required in order to invoke the Agent
    #' openai_4_1_mini <- ellmer::chat(
    #'     name = "openai/gpt-4.1-mini",
    #'     api_key = Sys.getenv("OPENAI_API_KEY"),
    #'     echo = "none"
    #' )
    #' agent <- Agent$new(
    #'  name = "translator",
    #'  instruction = "You are an Algerian citizen",
    #'  llm_object = openai_4_1_mini
    #' )
    #' agent$invoke("Continue this sentence: 1 2 3 viva")
    #' }
    invoke = function(prompt) {

      checkmate::assert_string(prompt)

      if (!is.null(self$budget)) {

        current_cost <- self$llm_object$get_cost()

        budget_exceeded <- current_cost > self$budget

        if (budget_exceeded) {
          cli::cli_abort(glue::glue(
            "{self$name} agent has exceeded its budget. Cost: {current_cost}, Budget: {self$budget}"
          ))
        }
      }

      private$.add_user_message(prompt)
      response <- self$llm_object$chat(prompt)
      response <- as.character(response)
      private$.add_assistant_message(response)
      return(response)
    },

    #' @description
    #' Set a budget to a specific agent, if the budget is reached, an error will be thrown
    #'
    #' @param amount_in_usd Numerical value denoting the amount to set for the budget,
    #' @examples \dontrun{
    #' # An API KEY is required in order to invoke the Agent
    #' openai_4_1_mini <- ellmer::chat(
    #'     name = "openai/gpt-4.1-mini",
    #'     api_key = Sys.getenv("OPENAI_API_KEY"),
    #'     echo = "none"
    #' )
    #' agent <- Agent$new(
    #'  name = "translator",
    #'  instruction = "You are an Algerian citizen",
    #'  llm_object = openai_4_1_mini
    #' )
    #' agent$set_budget(amount_in_usd = 10.5) # this is equivalent to 10.5$
    #' }
    set_budget = function(amount_in_usd) {

      checkmate::assert_number(amount_in_usd, lower = 0)

      self$budget <- amount_in_usd

      cli::cli_alert_success(glue::glue("Budget successfully set to {amount_in_usd}$"))

    },

    #' @description
    #' Keep only the most recent `n` messages, discarding older ones while keeping
    #' the system prompt.
    #' @param n Number of most recent messages to keep.
    #' @examples \dontrun{
    #' openai_4_1_mini <- ellmer::chat(
    #'   name = "openai/gpt-4.1-mini",
    #'   api_key = Sys.getenv("OPENAI_API_KEY"),
    #'   echo = "none"
    #' )
    #' agent <- Agent$new(
    #'   name = "capital finder",
    #'   instruction = "You are an assistant.",
    #'   llm_object = openai_4_1_mini
    #' )
    #' agent$invoke("What is the capital of Algeria")
    #' agent$invoke("What is the capital of Germany")
    #' agent$invoke("What is the capital of Italy")
    #' agent$keep_last_n_messages(n = 2)
    #' }
    keep_last_n_messages = function(n = 2) {

      checkmate::assert_integerish(n, lower = 1)

      ln_messags <- length(self$messages)

      messages_to_keep <- self$messages[(ln_messags - n + 1):ln_messags]

      system_prompt <- self$llm_object$get_system_prompt()

      tmp_sp <- list(
        list(role = "system", content = system_prompt)
      )

      private$._messages <- append(tmp_sp, messages_to_keep)

      private$.set_turns_from_messages()

      cli::cli_alert_success("Conversation truncated to last {n} messages.")

      invisible(self)

    },

    #' @description
    #' Summarises the agent's conversation history into a concise form and appends it
    #' to the system prompt. Unlike `update_instruction()`, this method does not override
    #' the existing instruction but augments it with a summary for future context.
    #'
    #' After creating the summary, the method clears the conversation history and
    #' retains only the updated system prompt. This ensures that subsequent interactions
    #' start fresh but with the summary preserved as context.
    #'
    #' @examples \dontrun{
    #'   # Requires an OpenAI-compatible LLM from `ellmer`
    #'   openai_4_1_mini <- ellmer::chat(
    #'     name = "openai/gpt-4.1-mini",
    #'     api_key = Sys.getenv("OPENAI_API_KEY"),
    #'     echo = "none"
    #'   )
    #'
    #'   agent <- Agent$new(
    #'     name = "summariser",
    #'     instruction = "You are a summarising assistant",
    #'     llm_object = openai_4_1_mini
    #'   )
    #'
    #'   agent$invoke("The quick brown fox jumps over the lazy dog.")
    #'   agent$invoke("This is another example sentence.")
    #'
    #'   # Summarises and resets history
    #'   agent$summarise_messages()
    #'
    #'   # Now only the system prompt (with summary) remains
    #'   agent$messages
    #' }

    clear_and_summarise_messages = function() {

      if (length(self$messages) <= 1) {
        cli::cli_alert_info("No conversation history to summarise.")
        return(invisible(NULL))
      }

      summary_prompt <- paste0(
        "Summarise the following conversation history in a concise paragraph:\n\n",
        paste(
          vapply(self$messages, function(m) {
            paste0(m$role, ": ", m$content)
          }, character(1)),
          collapse = " \n "
        )
      )

      summary <- self$llm_object$chat(summary_prompt)
      summary <- as.character(summary)

      new_system_prompt <- paste(
        self$instruction,
        "\n\n--- Conversation Summary ---\n",
        summary
      )

      self$llm_object$set_system_prompt(value = new_system_prompt)

      private$._messages <- list(
        list(role = "system", content = new_system_prompt)
      )

      private$.set_turns_from_messages()

      cli::cli_alert_success("Conversation history summarised and appended to system prompt.")
      cli::cli_alert_info("Summary: {substr(summary, 1, 100)}...")

      invisible(self)
    },

    #' @description
    #' Update the system prompt/instruction
    #' @param new_instruction New instruction to use. Not that the new instruction
    #' will override the old one
    #' @examples \dontrun{
    #' openai_4_1_mini <- ellmer::chat(
    #'   name = "openai/gpt-4.1-mini",
    #'   api_key = Sys.getenv("OPENAI_API_KEY"),
    #'   echo = "none"
    #' )
    #' agent <- Agent$new(
    #'   name = "assistant",
    #'   instruction = "You are an assistant.",
    #'   llm_object = openai_4_1_mini
    #' )
    #' agent$update_instruction("You are a concise assistant.")
    #' }
    update_instruction = function(new_instruction) {

      checkmate::assert_string(new_instruction)

      old_instruction <- self$instruction
      self$instruction <- new_instruction
      self$llm_object$set_system_prompt(value = new_instruction)

      private$._messages[[1]]$content <- new_instruction

      cli::cli_alert_success("Instruction successfully updated")
      cli::cli_alert_info("Old: {substr(old_instruction, 1, 50)}...")
      cli::cli_alert_info("New: {substr(new_instruction, 1, 50)}...")

      invisible(self)
    },

    #' @description
    #' Reset the agent's conversation history while keeping the system instruction
    #'
    #' @examples
    #' \dontrun{
    #' openai_4_1_mini <- ellmer::chat(
    #'   name = "openai/gpt-4.1-mini",
    #'   api_key = Sys.getenv("OPENAI_API_KEY"),
    #'   echo = "none"
    #' )
    #' agent <- Agent$new(
    #'   name = "AI assistant",
    #'   instruction = "You are an assistant.",
    #'   llm_object = openai_4_1_mini
    #')
    #' agent$invoke("Hello, how are you?")
    #' agent$invoke("Tell me about machine learning")
    #' agent$reset_conversation_history()  # Clears all messages except system prompt
    #' }
    reset_conversation_history = function() {
      system_prompt <- self$llm_object$get_system_prompt()

      private$._messages <- list(
        list(role = "system", content = system_prompt)
      )

      private$.set_turns_from_messages()

      cli::cli_alert_success("Conversation history reset. System prompt preserved.")
      invisible(self)
    },

    #' @description
    #' Saves the agent's current conversation history as a JSON file on disk.
    #' @param file_path Character string specifying the file path where the JSON
    #' file should be saved. Defaults to a file named
    #' `"<agent_name>_messages.json"` in the current working directory.
    #'
    #' @examples
    #' \dontrun{
    #' openai_4_1_mini <- ellmer::chat(
    #'   name = "openai/gpt-4.1-mini",
    #'   api_key = Sys.getenv("OPENAI_API_KEY"),
    #'   echo = "none"
    #' )
    #' agent <- Agent$new(
    #'   name = "capital_finder",
    #'   instruction = "You are an assistant.",
    #'   llm_object = openai_4_1_mini
    #')
    #' agent$invoke("What is the capital of Algeria")
    #' agent$invoke("What is the capital of Italy")
    #' agent$export_messages_history()
    #' }
    #'
    #' @seealso [load_messages_history()] for reloading a saved message history.
    #'
    export_messages_history = function(
    file_path = paste0(getwd(), "/", paste0(self$name, "_messages.json"))
    ) {

      checkmate::assert_string(file_path)

      jsonlite::write_json(
        self$messages,
        path = file_path,
        auto_unbox = TRUE,
        pretty = TRUE
      )

      cli::cli_alert_success(glue::glue("Conversation saved to {file_path}"))

    },

    #' @description
    #' Saves the agent's current conversation history as a JSON file on disk.
    #' @param file_path Character string specifying the file path where the JSON
    #' file is stored. Defaults to a file named
    #' `"<agent_name>_messages.json"` in the current working directory.
    #'
    #' @examples
    #' \dontrun{
    #' openai_4_1_mini <- ellmer::chat(
    #'   name = "openai/gpt-4.1-mini",
    #'   api_key = Sys.getenv("OPENAI_API_KEY"),
    #'   echo = "none"
    #' )
    #' agent <- Agent$new(
    #'   name = "capital_finder",
    #'   instruction = "You are an assistant.",
    #'   llm_object = openai_4_1_mini
    #')
    #' agent$load_messages_history("path/to/messages.json")
    #' agent$messages
    #' agent$llm_object
    #' }
    #'
    #' @seealso [export_messages_history()] for exporting the messages object to json.
    #'
    load_messages_history = function(
    file_path = paste0(getwd(), "/", paste0(self$name, "_messages.json"))
    ) {

      checkmate::assert_string(file_path)

      if (!file.exists(file_path)) {
        cli::cli_abort("File does not exist.")
      }

      messages <- jsonlite::read_json(file_path, simplifyVector = FALSE)

      self$messages <- messages

      cli::cli_alert_success(glue::glue("Conversation history loaded from {file_path}"))

    },

    #' @field name The agent's name.
    name = NULL,
    #' @field instruction The agent's role/system prompt.
    instruction = NULL,
    #' @field llm_object The underlying `ellmer::chat_openai` object.
    llm_object = NULL,
    #' @field agent_id A UUID uniquely identifying the agent.
    agent_id = NULL,
    #'@field model_provider The name of the entity providing the model (eg. OpenAI)
    model_provider = NULL,
    #'@field model_name The name of the model to be used (eg. gpt-4.1-mini)
    model_name = NULL,
    #'@field broadcast_history A list of all past broadcast interactions.
    broadcast_history = list(),
    #'@field budget A budget in $ that the agent should not exceed.
    budget = NULL
  ),

  active = list(
    #' @field messages Public active binding for the conversation history.
    #' Assignment is validated automatically.
    messages = function(value) {
      if (missing(value)) {
        return(private$._messages)
      }

      if (!is.list(value)) {
        cli::cli_abort("messages must be a list of message objects")
      }

      for (msg in value) {
        if (!is.list(msg) || !all(c("role", "content") %in% names(msg))) {
          cli::cli_abort("Each message must be a list with 'role' and 'content'")
        }
        if (!msg$role %in% c("system", "user", "assistant")) {
          cli::cli_abort(paste0("Invalid role: ", msg$role))
        }
      }

      private$._messages <- value

      private$.set_turns_from_messages()

    }
  ),

  private = list(
    ._messages = NULL,
    .add_message = function(message, type) {
      private$._messages[[length(private$._messages) + 1]] <- list(
        role = type,
        content = message
      )
    },

    .add_assistant_message = function(message, type = "assistant") {
      private$.add_message(message, type)
    },

    .add_user_message = function(message, type = "user") {
      private$.add_message(message, type)
    },

    .set_turns_from_messages = function() {

      messages <- self$messages
      turns <- list()

      for (msg in messages) {
        turn <- ellmer::Turn(
          role = msg$role,
          contents = list(ellmer::ContentText(msg$content))
        )
        turns <- append(turns, list(turn))
      }

      self$llm_object$set_turns(turns)

    }
  )
)
