#' Agent: A General-Purpose LLM Agent
#'
#' @description
#' The `Agent` class defines a modular LLM-based agent capable of responding to prompts using a defined role/instruction.
#' It wraps an OpenAI-compatible chat model via the [`ellmer`](https://github.com/llrs/ellmer) package.
#'
#' Each agent maintains its own message history and unique identity.
#'
#' @importFrom R6 R6Class
#' @importFrom uuid UUIDgenerate
#' @importFrom checkmate assert_string assert_flag assert_character assert_integerish
#' @importFrom checkmate assert_number
#' @importFrom cli cli_abort cli_alert_success cli_alert_warning cli_alert_info cli_rule cli_text cli_ul
#' @export
Agent <- R6::R6Class(
  classname = "Agent",

  public = list(
    #' @description
    #' Initializes a new Agent with a specific role/instruction.
    #'
    #' @param name A short identifier for the agent (e.g. `"translator"`).
    #' @param instruction The system prompt that defines the agent's role.
    #' @param llm_object The LLM object generate by ellmer (eg. output of ellmer::chat_openai)
    #' @examples
    #'   # An API KEY is required in order to invoke the Agent
    #'   openai_4_1_mini <- ellmer::chat(
    #'     name = "openai/gpt-4.1-mini",
    #'     api_key = Sys.getenv("OPENAI_API_KEY"),
    #'     echo = "none"
    #'   )
    #'
    #'   polar_bear_researcher <- Agent$new(
    #'     name = "POLAR BEAR RESEARCHER",
    #'     instruction = paste0(
    #'     "You are an expert in polar bears, ",
    #'     "you task is to collect information about polar bears. Answer in 1 sentence max."
    #'     ),
    #'     llm_object = openai_4_1_mini
    #'   )
    #'
    initialize = function(name, instruction, llm_object) {
      checkmate::assert_string(name)
      checkmate::assert_string(instruction)

      if (!"Chat" %in% class(llm_object)) {
        cli::cli_abort("The llm_object must be generated by ellmer")
      }

      self$name <- name
      self$instruction <- instruction
      self$llm_object <- llm_object$clone(deep = TRUE)

      meta_data <- self$llm_object$get_provider()
      self$model_provider <- meta_data@name
      self$model_name <- meta_data@model

      self$llm_object$set_system_prompt(value = instruction)

      private$._messages <- list(
        list(role = "system", content = instruction)
      )

      self$agent_id <- uuid::UUIDgenerate()

      # Budget tracking defaults
      self$budget <- Inf
      self$budget_unit <- "usd"
      self$spent_usd <- 0
      self$spent_tokens <- 0
      self$spent_calls <- 0
    },

    #' @description
    #' Sends a user prompt to the agent and returns the assistant's response.
    #'
    #' @param prompt A character string prompt for the agent to respond to.
    #' @return The LLM-generated response as a character string.
    #' @examples \dontrun{
    #' # An API KEY is required in order to invoke the Agent
    #' openai_4_1_mini <- ellmer::chat(
    #'     name = "openai/gpt-4.1-mini",
    #'     api_key = Sys.getenv("OPENAI_API_KEY"),
    #'     echo = "none"
    #' )
    #' agent <- Agent$new(
    #'  name = "translator",
    #'  instruction = "You are an Algerian citizen",
    #'  llm_object = openai_4_1_mini
    #' )
    #' agent$invoke("Continue this sentence: 1 2 3 viva")
    #' }
    invoke = function(prompt) {
      checkmate::assert_string(prompt)
      private$.add_user_message(prompt)
      response <- self$chat_with_budget(prompt)
      private$.add_assistant_message(response)
      return(response)
    },

    #' @description
    #' Set a budget for the agent and choose the unit to enforce on.
    #' Supported units are: "usd" (dollars), "tokens" (sum of prompt+completion), "calls" (number of chat calls).
    #' @param value Non-negative numeric budget value. Use Inf to disable.
    #' @param unit One of "usd", "tokens", or "calls".
    #' @examples \dontrun{
    #'   agent$set_budget(0.02, unit = "usd")
    #'   agent$set_budget(2000, unit = "tokens")
    #'   agent$set_budget(5, unit = "calls")
    #' }
    set_budget = function(value, unit = c("usd", "tokens", "calls")) {
      unit <- match.arg(unit)
      checkmate::assert_number(value, lower = 0, finite = FALSE)
      self$budget <- value
      self$budget_unit <- unit
      invisible(self)
    },

    #' @description
    #' Reset the tracked spend counters to zero.
    reset_spend = function() {
      self$spent_usd <- 0
      self$spent_tokens <- 0
      self$spent_calls <- 0
      invisible(self)
    },

    #' @description
    #' Get the current spend counters.
    #' @return A named list with usd, tokens, and calls spent so far.
    get_spend = function() {
      list(
        usd = self$spent_usd,
        tokens = self$spent_tokens,
        calls = self$spent_calls
      )
    },

    #' @description
    #' Low-level chat wrapper that enforces budget and records spend.
    #' Prefer using invoke() unless you need a raw chat with the LLM.
    #' @param prompt The prompt to send to the underlying LLM.
    #' @return The model's response as a character string.
    chat_with_budget = function(prompt) {
      checkmate::assert_string(prompt)

      # Pre-check for call-count budget
      if (identical(self$budget_unit, "calls") && is.finite(self$budget)) {
        if ((self$spent_calls + 1) > self$budget) {
          cli::cli_abort(
            "Budget reached: next call would exceed the allowed number of calls ({self$budget})."
          )
        }
      }

      before_stats <- private$.llm_parse_stats()
      before_usd <- before_stats$usd
      before_tokens <- before_stats$tokens

      result <- self$llm_object$chat(prompt)

      after_stats <- private$.llm_parse_stats()
      after_usd <- after_stats$usd
      after_tokens <- after_stats$tokens

      delta_usd <- 0
      delta_tokens <- 0
      if (!is.na(before_usd) && !is.na(after_usd)) {
        delta_usd <- max(0, after_usd - before_usd)
      }
      if (!is.na(before_tokens) && !is.na(after_tokens)) {
        delta_tokens <- max(0, after_tokens - before_tokens)
      }

      # Update counters
      self$spent_calls <- self$spent_calls + 1
      self$spent_usd <- self$spent_usd + delta_usd
      self$spent_tokens <- self$spent_tokens + delta_tokens

      # Enforce budgets post-call
      private$.enforce_budget_or_abort()

      return(result)
    },

    #' @description
    #' Keep only the most recent `n` messages, discarding older ones while keeping
    #' the system prompt.
    #' @param n Number of most recent messages to keep.
    #' @examples \dontrun{
    #' openai_4_1_mini <- ellmer::chat(
    #'   name = "openai/gpt-4.1-mini",
    #'   api_key = Sys.getenv("OPENAI_API_KEY"),
    #'   echo = "none"
    #' )
    #' agent <- Agent$new(
    #'   name = "capital finder",
    #'   instruction = "You are an assistant.",
    #'   llm_object = openai_4_1_mini
    #' )
    #' agent$invoke("What is the capital of Algeria")
    #' agent$invoke("What is the capital of Germany")
    #' agent$invoke("What is the capital of Italy")
    #' agent$keep_last_n_messages(n = 2)
    #' }
    keep_last_n_messages = function(n = 2) {

      checkmate::assert_integerish(n, lower = 1)

      ln_messags <- length(self$messages)

      messages_to_keep <- self$messages[(ln_messags - n + 1):ln_messags]

      system_prompt <- self$llm_object$get_system_prompt()

      tmp_sp <- list(
        list(role = "system", content = system_prompt)
      )

      private$._messages <- append(tmp_sp, messages_to_keep)

      private$.set_turns_from_messages()

      cli::cli_alert_success("Conversation truncated to last {n} messages.")

      invisible(self)

    },

    #' @description
    #' Summarises the agent's conversation history into a concise form and appends it
    #' to the system prompt. Unlike `update_instruction()`, this method does not override
    #' the existing instruction but augments it with a summary for future context.
    #'
    #' After creating the summary, the method clears the conversation history and
    #' retains only the updated system prompt. This ensures that subsequent interactions
    #' start fresh but with the summary preserved as context.
    #'
    #' @examples \dontrun{
    #'   # Requires an OpenAI-compatible LLM from `ellmer`
    #'   openai_4_1_mini <- ellmer::chat(
    #'     name = "openai/gpt-4.1-mini",
    #'     api_key = Sys.getenv("OPENAI_API_KEY"),
    #'     echo = "none"
    #'   )
    #'
    #'   agent <- Agent$new(
    #'     name = "summariser",
    #'     instruction = "You are a summarising assistant",
    #'     llm_object = openai_4_1_mini
    #'   )
    #'
    #'   agent$invoke("The quick brown fox jumps over the lazy dog.")
    #'   agent$invoke("This is another example sentence.")
    #'
    #'   # Summarises and resets history
    #'   agent$summarise_messages()
    #'
    #'   # Now only the system prompt (with summary) remains
    #'   agent$messages
    #' }

    clear_and_summarise_messages = function() {

      if (length(self$messages) <= 1) {
        cli::cli_alert_info("No conversation history to summarise.")
        return(invisible(NULL))
      }

      summary_prompt <- paste0(
        "Summarise the following conversation history in a concise paragraph:\n\n",
        paste(
          vapply(self$messages, function(m) {
            paste0(m$role, ": ", m$content)
          }, character(1)),
          collapse = " \n "
        )
      )

      summary <- self$llm_object$chat(summary_prompt)

      new_system_prompt <- paste(
        self$instruction,
        "\n\n--- Conversation Summary ---\n",
        summary
      )

      self$llm_object$set_system_prompt(value = new_system_prompt)

      private$._messages <- list(
        list(role = "system", content = new_system_prompt)
      )

      private$.set_turns_from_messages()

      cli::cli_alert_success("Conversation history summarised and appended to system prompt.")
      cli::cli_alert_info("Summary: {substr(summary, 1, 100)}...")

      invisible(self)
    },

    #' @description
    #' Update the system prompt/instruction
    #' @param new_instruction New instruction to use. Not that the new instruction
    #' will override the old one
    #' @examples \dontrun{
    #' openai_4_1_mini <- ellmer::chat(
    #'   name = "openai/gpt-4.1-mini",
    #'   api_key = Sys.getenv("OPENAI_API_KEY"),
    #'   echo = "none"
    #' )
    #' agent <- Agent$new(
    #'   name = "assistant",
    #'   instruction = "You are an assistant.",
    #'   llm_object = openai_4_1_mini
    #' )
    #' agent$update_instruction("You are a concise assistant.")
    #' }
    update_instruction = function(new_instruction) {

      checkmate::assert_string(new_instruction)

      old_instruction <- self$instruction
      self$instruction <- new_instruction
      self$llm_object$set_system_prompt(value = new_instruction)

      private$._messages[[1]]$content <- new_instruction

      cli::cli_alert_success("Instruction successfully updated")
      cli::cli_alert_info("Old: {substr(old_instruction, 1, 50)}...")
      cli::cli_alert_info("New: {substr(new_instruction, 1, 50)}...")

      invisible(self)

    },

    #' @field name The agent's name.
    name = NULL,
    #' @field instruction The agent's role/system prompt.
    instruction = NULL,
    #' @field llm_object The underlying `ellmer::chat_openai` object.
    llm_object = NULL,
    #' @field agent_id A UUID uniquely identifying the agent.
    agent_id = NULL,
    #'@field model_provider The name of the entity providing the model (eg. OpenAI)
    model_provider = NULL,
    #'@field model_name The name of the model to be used (eg. gpt-4.1-mini)
    model_name = NULL,
    #'@field broadcast_history A list of all past broadcast interactions.
    broadcast_history = list(),
    #' @field budget Configured budget value (numeric); Inf by default (no limit).
    budget = NULL,
    #' @field budget_unit Unit of the budget: one of "usd", "tokens", or "calls".
    budget_unit = NULL,
    #' @field spent_usd Accumulated USD spent as tracked via LLM stats.
    spent_usd = NULL,
    #' @field spent_tokens Accumulated tokens spent (prompt + completion).
    spent_tokens = NULL,
    #' @field spent_calls Number of LLM chat calls performed by this agent.
    spent_calls = NULL
  ),

  active = list(
    #' @field messages Public active binding for the conversation history.
    #' Assignment is validated automatically.
    messages = function(value) {
      if (missing(value)) {
        return(private$._messages)
      }

      if (!is.list(value)) {
        cli::cli_abort("messages must be a list of message objects")
      }

      for (msg in value) {
        if (!is.list(msg) || !all(c("role", "content") %in% names(msg))) {
          cli::cli_abort("Each message must be a list with 'role' and 'content'")
        }
        if (!msg$role %in% c("system", "user", "assistant")) {
          cli::cli_abort(paste0("Invalid role: ", msg$role))
        }
      }

      private$._messages <- value

      private$.set_turns_from_messages()

    }
  ),

  private = list(
    ._messages = NULL,
    .add_message = function(message, type) {
      private$._messages[[length(private$._messages) + 1]] <- list(
        role = type,
        content = message
      )
    },

    .add_assistant_message = function(message, type = "assistant") {
      private$.add_message(message, type)
    },

    .add_user_message = function(message, type = "user") {
      private$.add_message(message, type)
    },

    .set_turns_from_messages = function() {

      messages <- self$messages
      turns <- list()

      for (msg in messages) {
        turn <- ellmer::Turn(
          role = msg$role,
          contents = list(ellmer::ContentText(msg$content))
        )
        turns <- append(turns, list(turn))
      }

      self$llm_object$set_turns(turns)

    }
    ,
    # Parse LLM object printed header to extract tokens and usd, best-effort.
    .llm_parse_stats = function() {
      # Expected header example:
      # <Chat OpenAI/gpt-4.1-mini turns=3 tokens=43/21 $0.00>
      header <- NA_character_
      out <- utils::capture.output(self$llm_object)
      if (length(out) >= 1) header <- out[[1]]

      usd <- NA_real_
      tokens <- NA_real_

      if (!is.na(header)) {
        # Extract cost
        m_cost <- regexec("\\$([0-9]+(?:\\.[0-9]+)?)", header)
        reg_cost <- regmatches(header, m_cost)
        if (length(reg_cost) == 1 && length(reg_cost[[1]]) >= 2) {
          usd <- suppressWarnings(as.numeric(reg_cost[[1]][2]))
        }

        # Extract tokens a/b and sum them
        m_tok <- regexec("tokens=([0-9]+)\/([0-9]+)", header)
        reg_tok <- regmatches(header, m_tok)
        if (length(reg_tok) == 1 && length(reg_tok[[1]]) >= 3) {
          a <- suppressWarnings(as.numeric(reg_tok[[1]][2]))
          b <- suppressWarnings(as.numeric(reg_tok[[1]][3]))
          if (!is.na(a) && !is.na(b)) tokens <- a + b
        }
      }

      list(usd = usd, tokens = tokens)
    },

    .enforce_budget_or_abort = function() {
      if (!is.finite(self$budget)) return(invisible(NULL))

      unit <- self$budget_unit
      exceeded <- FALSE
      used <- NA_real_

      if (identical(unit, "usd")) {
        used <- self$spent_usd
        exceeded <- used > self$budget
      } else if (identical(unit, "tokens")) {
        used <- self$spent_tokens
        exceeded <- used > self$budget
      } else if (identical(unit, "calls")) {
        used <- self$spent_calls
        exceeded <- used > self$budget
      }

      if (isTRUE(exceeded)) {
        cli::cli_abort(
          "Budget exceeded: used {round(used, 4)} {unit} (limit = {self$budget})."
        )
      }

      invisible(NULL)
    }
  )
)
